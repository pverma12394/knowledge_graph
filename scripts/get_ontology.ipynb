{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2772a980",
   "metadata": {},
   "source": [
    "# Get ontology data from OBO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa651e32-3078-48b0-9a53-b717308d400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kanak/elucidata/envs/kg_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd4255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install pronto --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0546dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5221355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on terminal\n",
    "!polly files sync --workspace-id 9475 --source polly:// --destination ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1e27a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BTO (Brenda Tissue Ontology) - Tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read obo file\n",
    "bto = pronto.Ontology(\"/Users/kanak/Downloads/tissue.obo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38a8d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch node properties for tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592dec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1789, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bto_id = []\n",
    "bto_name = []\n",
    "bto_def = []\n",
    "bto_syn = []\n",
    "\n",
    "for terms in bto.terms():\n",
    "    temp = []\n",
    "    if('tissue' in list(terms.subsets)[0]):\n",
    "        bto_id.append(str(terms.id))\n",
    "        bto_name.append(str(terms.name))\n",
    "        bto_def.append(str(terms.definition))\n",
    "        syn = list(terms.synonyms)\n",
    "        for s in syn:\n",
    "            temp.append(str(str(s).split(\"'\")[1]))\n",
    "        bto_syn.append(','.join(temp))\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "bto_df = pd.DataFrame(list(zip(bto_id, bto_name, bto_def, bto_syn)), columns = ['tissue_id', 'name', 'definition', 'synonyms'])\n",
    "bto_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0845cd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch relationships for tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921b7191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bto_sub = []\n",
    "bto_id = []\n",
    "\n",
    "for terms in bto.terms():\n",
    "    temp = []\n",
    "    if('tissue' in list(terms.subsets)[0]):\n",
    "        sub = terms.subclasses(with_self = False, distance = 1)\n",
    "        for s in sub:\n",
    "            temp.append(str(s.id))\n",
    "        bto_id.append(terms.id)\n",
    "        bto_sub.append(temp)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "sub_df = pd.DataFrame(list(zip(bto_id, bto_sub)), columns = ['tissue', 'subclass'])\n",
    "sub_df = sub_df.explode('subclass')\n",
    "sub_df = sub_df.dropna(subset= ['subclass'])\n",
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8824ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bearer_of', 'causually_influences', 'contained_in', 'develops_from', 'disease_arises_from_structure', 'disease_causes_dysfunction_of', 'part_of', 'produced_by', 'realized_in']\n"
     ]
    }
   ],
   "source": [
    "rels = []\n",
    "for r in bto.relationships():\n",
    "    rels.append(r.id)\n",
    "    \n",
    "print(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e46a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bto_part = []\n",
    "bto_rel = []\n",
    "bto_id = []\n",
    "\n",
    "for terms in bto.terms():\n",
    "    if('tissue' in list(terms.subsets)[0]):\n",
    "        for rel in rels:\n",
    "            if rel in str(list(terms.relationships)):\n",
    "                try:\n",
    "                    ts = terms.relationships[bto.get_relationship(rel)]\n",
    "                    bto_id.append(str(terms.id))\n",
    "                    bto_rel.append(rel)\n",
    "                    bto_part.append(str(list(ts)[0].id))\n",
    "                except:\n",
    "                    print(terms.id)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "rel_df = pd.DataFrame(list(zip(bto_id, bto_rel ,bto_part)), columns = ['tissue_id', 'relation', 'target'])\n",
    "rel_df = rel_df.explode('target')\n",
    "rel_df = rel_df.dropna(subset= ['target'])\n",
    "rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in rels:\n",
    "    df = rel_df[rel_df['relation'] == rel]\n",
    "    df.to_csv(f\"graph_data/tissue__{rel}__relation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a934c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bto_df.to_csv('graph_data/tissue__nodes.csv', index=False)\n",
    "sub_df.to_csv('graph_data/tissue__subclass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345d486",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cell Type Ontology - BTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac296efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read obo file\n",
    "cto = pronto.Ontology( \"/Users/kanak/Downloads/tissue.obo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebeb4ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cto_id = []\n",
    "cto_name = []\n",
    "cto_def = []\n",
    "cto_syn = []\n",
    "\n",
    "for terms in cto.terms():\n",
    "    temp = []\n",
    "    if('cell_type' in list(terms.subsets)[0]):\n",
    "        cto_id.append(str(terms.id))\n",
    "        cto_name.append(str(terms.name))\n",
    "        cto_def.append(str(terms.definition))\n",
    "        syn = list(terms.synonyms)\n",
    "        for s in syn:\n",
    "            temp.append(str(str(s).split(\"'\")[1]))\n",
    "        cto_syn.append(','.join(temp))\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "cto_df = pd.DataFrame(list(zip(cto_id, cto_name, cto_def, cto_syn)), columns = ['cell_type_id', 'name', 'definition', 'synonyms'])\n",
    "cto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf01a053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cto_sub = []\n",
    "cto_id = []\n",
    "\n",
    "for terms in cto.terms():\n",
    "    temp = []\n",
    "    if('cell_type' in list(terms.subsets)[0]):\n",
    "        sub = terms.subclasses(with_self = False, distance = 1)\n",
    "        for s in sub:\n",
    "            temp.append(str(s.id))\n",
    "        cto_id.append(terms.id)\n",
    "        cto_sub.append(temp)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "sub_df = pd.DataFrame(list(zip(cto_id, cto_sub)), columns = ['cell_type_id', 'subclass'])\n",
    "sub_df = sub_df.explode('subclass')\n",
    "sub_df = sub_df.dropna(subset= ['subclass'])\n",
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf0a6f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'develops_from',\n",
       " 'disease_arises_from_structure',\n",
       " 'disease_causes_dysfunction_of',\n",
       " 'part_of',\n",
       " 'realized_in'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_rels = set()\n",
    "for terms in cto.terms():\n",
    "    if('cell_type' in list(terms.subsets)[0]):\n",
    "        for rel in cto.relationships():\n",
    "            if rel.id in str(list(terms.relationships)):\n",
    "                cell_type_rels.add(rel.id)\n",
    "\n",
    "cell_type_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d71db711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTO:0001413\n",
      "BTO:0003801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(498, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cto_part = []\n",
    "cto_rel = []\n",
    "cto_id = []\n",
    "\n",
    "for terms in cto.terms():\n",
    "    if('cell_type' in list(terms.subsets)[0]):\n",
    "        for rel in cell_type_rels:\n",
    "            if rel in str(list(terms.relationships)):\n",
    "                try:\n",
    "                    ts = terms.relationships[cto.get_relationship(rel)]\n",
    "                    cto_id.append(str(terms.id))\n",
    "                    cto_rel.append(rel)\n",
    "                    cto_part.append(str(list(ts)[0].id))\n",
    "                except:\n",
    "                    print(terms.id)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "rel_df = pd.DataFrame(list(zip(cto_id, cto_rel ,cto_part)), columns = ['cell_type_id', 'relation', 'target'])\n",
    "rel_df = rel_df.explode('target')\n",
    "rel_df = rel_df.dropna(subset= ['target'])\n",
    "rel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in cell_type_rels:\n",
    "    df = rel_df[rel_df['relation'] == rel]\n",
    "    df.to_csv(f\"graph_data/cell_type__{rel}__relation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cto_df.to_csv('graph_data/cell_type__nodes.csv', index=False)\n",
    "sub_df.to_csv('graph_data/cell_type__subclass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4aa0c",
   "metadata": {},
   "source": [
    "## Cell Line ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_v3 = pronto.Ontology('ontologies/obo/cellosaurus-edited-v3.obo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_id = []\n",
    "clo_name = []\n",
    "clo_category = []\n",
    "clo_syn = []\n",
    "clo_gender = []\n",
    "\n",
    "gender_terms = ['Male','Female','Mixed_sex','Sex_ambiguous','Sex_unspecified']\n",
    "\n",
    "for terms in clo_v3.terms():\n",
    "    temp = []\n",
    "    clo_id.append(str(terms.id))\n",
    "    clo_name.append(str(terms.name))\n",
    "    if len(list(terms.subsets)) == 2:\n",
    "        if str(list(terms.subsets)[0]) in gender_terms:\n",
    "            clo_gender.append(str(list(terms.subsets)[0]).replace('_',' '))\n",
    "            clo_category.append(str(list(terms.subsets)[1]).replace('_',' '))\n",
    "        elif str(list(terms.subsets)[1]) in gender_terms:\n",
    "            clo_gender.append(str(list(terms.subsets)[1]).replace('_',' '))\n",
    "            clo_category.append(str(list(terms.subsets)[0]).replace('_',' '))\n",
    "    else:\n",
    "        if str(list(terms.subsets)[0]) in gender_terms:\n",
    "            clo_gender.append(str(list(terms.subsets)[0]).replace('_',' '))\n",
    "            clo_category.append(\" \")\n",
    "        else:\n",
    "            clo_gender.append(\" \")\n",
    "            clo_category.append(str(list(terms.subsets)[0]).replace('_',' '))\n",
    "\n",
    "    syn = list(terms.synonyms)\n",
    "    for s in syn:\n",
    "        temp.append(str(str(s).split(\"'\")[1]))\n",
    "    clo_syn.append(','.join(temp))\n",
    "    \n",
    "# print('id:',len(clo_id))\n",
    "# print('name:',len(clo_name))\n",
    "# print('gender:',len(clo_gender))\n",
    "# print('category:',len(clo_category))\n",
    "# print('synonyms:',len(clo_syn))\n",
    "        \n",
    "class_df = pd.DataFrame(list(zip(clo_id, clo_name, clo_gender,clo_category, clo_syn)), columns = ['cell_line_id', 'name', 'gender','category', 'synonyms'])\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(class_df['category'])\n",
    "# set(class_df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting cell_line-disease from another obo file\n",
    "clo_2 = pronto.Ontology('ontologies/obo/cell_line.obo')\n",
    "\n",
    "clo_dis = []\n",
    "clo_id = []        \n",
    "\n",
    "for term in clo_2.terms():\n",
    "    for xref in term.xrefs:\n",
    "        if xref.id.startswith(\"MESH\"):\n",
    "            clo_id.append(term.id)\n",
    "            clo_dis.append(xref.id)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "dis = pd.DataFrame(list(zip(clo_id, clo_dis)), columns = ['cell_line_id', 'disease'])   \n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis.to_csv('graph_data/cell_line__disease.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12442799",
   "metadata": {},
   "source": [
    "### Linking Tissue to Cell-Line Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5197433",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = pd.read_csv('tissue_cell_line.csv')\n",
    "cell_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955cf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean tissue column\n",
    "#Create a secondary tissue column\n",
    "cell_df['secondary_tissue'] = cell_df['Tissue'].str.split(';').str[1]\n",
    "cell_df['secondary_tissue'] = cell_df['secondary_tissue'].str.strip(' ')\n",
    "#Tissue column only includes the primary tissue terms\n",
    "cell_df['Tissue'] = cell_df['Tissue'].str.split(';').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aee5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean tissue column\n",
    "for index, row in cell_df.iterrows():\n",
    "    if '=' in str(row['Tissue']):\n",
    "        row['Tissue'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c87010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset using CLO\n",
    "cell_df = cell_df[cell_df['ACC'].isin(class_df['cell_line_id'])]\n",
    "#drop Na in Tissue\n",
    "cell_df = cell_df.dropna(subset=['Tissue'])\n",
    "cell_df['Tissue'] = cell_df['Tissue'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map tissue terms to BTO\n",
    "\n",
    "bto_clo = bto_df.merge(cell_df, how='inner', left_on='name', right_on='Tissue')\n",
    "bto_clo = bto_clo[['tissue_id', 'ACC']]\n",
    "bto_clo.columns = ['tissue', 'cell_line']\n",
    "bto_clo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bto_clo.to_csv('graph_data/tissue__cell_line.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70002c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rels_clo = []\n",
    "for r in clo_v3.relationships():\n",
    "    rels_clo.append(r.id)\n",
    "    \n",
    "rels_clo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f173eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_tar = []\n",
    "clo_rel = []\n",
    "clo_id = []\n",
    "\n",
    "for terms in clo_v3.terms():\n",
    "    for rel in rels_clo:\n",
    "        if rel in str(list(terms.relationships)):\n",
    "            ts = terms.relationships[clo_v3.get_relationship(rel)]\n",
    "            clo_id.append(str(terms.id))\n",
    "            clo_rel.append(rel)\n",
    "            clo_tar.append(str(list(ts)[0].id))\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "rel_df = pd.DataFrame(list(zip(clo_id, clo_rel ,clo_tar)), columns = ['cell_line_id', 'relation', 'target'])\n",
    "rel_df = rel_df.explode('target')\n",
    "rel_df = rel_df.dropna(subset= ['target'])\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in rels_clo:\n",
    "    df = rel_df[rel_df['relation'] == rel]\n",
    "    df.to_csv(f\"graph_data/cell_line__{rel}__relation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2048c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.to_csv('graph_data/cell_line__nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a26f856",
   "metadata": {},
   "source": [
    "## MeSH Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf518916",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = pronto.Ontology('ontologies/obo/disease.obo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_id = []\n",
    "mesh_name = []\n",
    "mesh_syn = []\n",
    "\n",
    "for terms in mesh.terms():\n",
    "    temp = []\n",
    "    mesh_id.append(str(terms.id))\n",
    "    mesh_name.append(str(terms.name))\n",
    "    syn = list(terms.synonyms)\n",
    "    for s in syn:\n",
    "        temp.append(str(str(s).split(\"'\")[1]))\n",
    "    mesh_syn.append(','.join(temp))\n",
    "        \n",
    "class_df = pd.DataFrame(list(zip(mesh_id, mesh_name, mesh_syn)), columns = ['id', 'name', 'synonyms'])\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_sub = []\n",
    "mesh_id = []\n",
    "\n",
    "for terms in mesh.terms():\n",
    "    temp = []\n",
    "    mesh = terms.subclasses(with_self = False, distance = 1)\n",
    "    for m in mesh:\n",
    "        temp.append(str(m.id))\n",
    "    mesh_id.append(terms.id)\n",
    "    mesh_sub.append(temp)\n",
    "    \n",
    "        \n",
    "sub_df = pd.DataFrame(list(zip(mesh_id, mesh_sub)), columns = ['disease', 'subclass'])\n",
    "sub_df = sub_df.explode('subclass')\n",
    "sub_df = sub_df.dropna(subset= ['subclass'])\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.to_csv('graph_data/disease__nodes.csv', index=False)\n",
    "sub_df.to_csv('graph_data/disease__subclass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c541ae",
   "metadata": {},
   "source": [
    "### Disease Gene Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07068c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Process,Manager\n",
    "from harmonizomeapi import Harmonizome, Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93070686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_json(addr):\n",
    "\turl = base_url + addr\n",
    "\tresponse = requests.get(url)\n",
    "\n",
    "\tif response.status_code == 200:\n",
    "\t\ttry:\n",
    "\t\t\tdata = json.loads(response.text)\n",
    "\t\t\treturn data\n",
    "\t\texcept:\n",
    "\t\t\treturn \" \"\n",
    "\t\n",
    "\telse:\n",
    "\t\tprint(\"Error\")\n",
    "\t\tprint(addr)\n",
    "\n",
    "\n",
    "\n",
    "def get_mesh_id(disease):\n",
    "    try:\n",
    "        mesh_request = requests.get(\"http://id.nlm.nih.gov/mesh/lookup/descriptor\",params={'label':disease})\n",
    "        mesh_response = mesh_request.json()[0]['resource'].split('/')\n",
    "        mesh_id = mesh_response[len(mesh_response) - 1]\n",
    "        return mesh_id\n",
    "    except:\n",
    "        print('Error while finding in disease - ', disease)\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_name_to_url(name):\n",
    "\t\n",
    "\tdef Convert(string):\n",
    "\t\tlist1=[]\n",
    "\t\tlist1[:0]=string\n",
    "\t\treturn list1\n",
    "\n",
    "\tname_lst1 = Convert(name)\n",
    "\tname_lst2 = name_lst1[:]\n",
    "\n",
    "\tfor i in range(len(name_lst1)):\n",
    "\t\tif name_lst1[i] == ',':\n",
    "\t\t\tname_lst1[i] = '%'\n",
    "\t\t\tname_lst2[i] = '%2C'\n",
    "\n",
    "\t\telif name_lst1[i] == \" \":\n",
    "\t\t\tname_lst1[i] = \"+\"\n",
    "\t\t\tname_lst2[i] = \"+\"\n",
    "\n",
    "\turl_name1 = \"\"\n",
    "\tfor i in name_lst1:\n",
    "\t\turl_name1 += i\n",
    "\n",
    "\turl_name2 = \"\"\n",
    "\tfor i in name_lst2:\n",
    "\t\turl_name2 += i\n",
    "\n",
    "\n",
    "\turl1 = \"https://maayanlab.cloud/Harmonizome/gene_set/\" + url_name1 + \"/CTD+Gene-Disease+Associations\"\n",
    "\turl2 = \"https://maayanlab.cloud/Harmonizome/gene_set/\" + url_name2 + \"/CTD+Gene-Disease+Associations\"\n",
    "\n",
    "\thtml2 = requests.get(url2)\n",
    "\n",
    "\tif html2.status_code == 200:\n",
    "\t\treturn url2\n",
    "\telse:\n",
    "\t\treturn url1\n",
    "\n",
    "def find_mesh_id(url):\n",
    "\thtml_text = requests.get(url).text\n",
    "\tsoup = BeautifulSoup(html_text,'html.parser')\n",
    "\n",
    "\tfor link in soup.find_all('a'):\n",
    "\t\tlink_url = link.get('href')\n",
    "\t\tif \"ctdbase.org\" in link_url:\n",
    "\t\t\tmesh_id = link_url.split('=')[-1]\n",
    "\t\t\t# mesh, ID = mesh_id.split(':')\n",
    "\t\t\treturn mesh_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f45e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_gene_associations(genesets,num,return_dict):\n",
    "    dis_gene_dict = {'Disease_Name':[],\n",
    "                    'ID':[],\n",
    "                    'Associated_Gene_Symbols':[]}\n",
    "    \n",
    "    for geneset in genesets:\n",
    "        disease_name = geneset['name'].split('/')[0]\n",
    "        dis_gene_dict['Disease_Name'].append(disease_name)\n",
    "        \n",
    "        gene_info = return_json(geneset['href'])\n",
    "        genes = \"\"\n",
    "        for j in range(len(gene_info['associations'])):\n",
    "            genes += gene_info['associations'][j]['gene']['symbol']\n",
    "            if j != len(gene_info['associations'])-1:\n",
    "                genes += ','\n",
    "        dis_gene_dict['Associated_Gene_Symbols'].append(genes)\n",
    "        \n",
    "        url = convert_name_to_url(disease_name)\n",
    "        mesh_id = find_mesh_id(url)\n",
    "        dis_gene_dict['ID'].append(mesh_id)\n",
    "        \n",
    "#     return dis_gene_dict\n",
    "    return_dict[num]=dis_gene_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3673d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lst = Harmonizome.get(Entity.DATASET)\n",
    "\n",
    "base_url = \"https://maayanlab.cloud/Harmonizome\"\n",
    "\n",
    "# The dataset CTD - Disease Gene Associations\n",
    "dataset = return_json(dataset_lst['entities'][24]['href'])['geneSets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 15\n",
    "\n",
    "return_dict = Manager().dict()\n",
    "jobs = []\n",
    "\n",
    "for i in range(num_processes):\n",
    "    lb = i*math.ceil(len(dataset)/num_processes)\n",
    "    up = min((i+1)*math.ceil(len(dataset)/num_processes),len(dataset))\n",
    "    \n",
    "    p = Process(target=disease_gene_associations,args=(dataset[lb:up],i,return_dict))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "    \n",
    "for process in jobs:\n",
    "    print()\n",
    "    process.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3422128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for process in jobs:\n",
    "    print(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "for i in range(len(return_dict)):\n",
    "    df_lst.append(pd.DataFrame(return_dict[i]))\n",
    "    \n",
    "df = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(row):\n",
    "\t# print(row)\n",
    "\tif str(row['Associated_Gene_Symbols']) != 'nan':\n",
    "\t\treturn row['Associated_Gene_Symbols'].split(',')\n",
    "\telse:\n",
    "\t\treturn []\n",
    "\n",
    "df['Associated_Genes'] = df.apply(to_list,axis=1)\n",
    "df = df[['ID','Associated_Genes']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fab9c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_dis = pd.read_csv(\"mesh_diseases.csv\")\n",
    "dis = mesh_dis[['ID']]\n",
    "\n",
    "final_df = pd.merge(df,dis,on='ID',how='inner')\n",
    "final_df = final_df.explode('Associated_Genes')\n",
    "final_df = final_df.dropna(subset=['Associated_Genes'])\n",
    "final_df.columns = ['disease_id','gene']\n",
    "final_df.to_csv(\"graph_data/disease__gene.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffd49c",
   "metadata": {},
   "source": [
    "### Gene Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222326be",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = Harmonizome.get(Entity.GENE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_lst = []\n",
    "\n",
    "for i in range(568):\n",
    "    for j in range(len(genes['entities'])):\n",
    "        gene_lst.append(genes['entities'][j]['symbol'])\n",
    "    if i != 567:\n",
    "        genes = Harmonizome.next(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_json(url):\n",
    "\tresponse = requests.get(url)\n",
    "\n",
    "\tif response.status_code == 200:\n",
    "\t\tdata = json.loads(response.text)\n",
    "\t\treturn data\n",
    "    \n",
    "\telse:\n",
    "\t\treturn {\"symbol\":\"\",\n",
    "                \"synonyms\":[],\n",
    "                \"name\":\"\",\n",
    "                \"description\":\"\",\n",
    "                \"ncbiEntrezGeneId\":-1,\n",
    "                \"ncbiEntrezGeneUrl\":\"\",\n",
    "                \"proteins\":[],\n",
    "                \"hgncRootFamilies\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819402e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_properties(gene_lst,num,return_dict):\n",
    "    base_url = \"https://maayanlab.cloud/Harmonizome/api/1.0/gene/\"\n",
    "    \n",
    "    gene_prop_dict = {\"Gene_Symbol\":[],\n",
    "                     \"Synonyms\":[],\n",
    "                     \"Gene_Name\":[],\n",
    "                     \"Description\":[],\n",
    "                     \"NcbiEntrezGeneId\":[],\n",
    "                     \"NcbiEntrezGeneUrl\":[],\n",
    "                     \"Proteins\":[],\n",
    "                     \"HgncRootFamilies\":[]}\n",
    "    \n",
    "    for gene in gene_lst:\n",
    "        url = base_url + gene\n",
    "        gene_props = return_json(url)\n",
    "        gene_prop_dict['Gene_Symbol'].append(gene)\n",
    "        \n",
    "        synonyms = \"\"\n",
    "        if gene_props['synonyms'] != []:\n",
    "            for i in range(len(gene_props['synonyms'])):\n",
    "                synonyms += gene_props['synonyms'][i]\n",
    "                if i != len(gene_props['synonyms'])-1:\n",
    "                    synonyms += ','\n",
    "        gene_prop_dict['Synonyms'].append(synonyms)\n",
    "        \n",
    "        gene_prop_dict['Gene_Name'].append(gene_props['name'])\n",
    "        gene_prop_dict['Description'].append(gene_props['description'])\n",
    "        gene_prop_dict['NcbiEntrezGeneId'].append(gene_props['ncbiEntrezGeneId'])\n",
    "        gene_prop_dict['NcbiEntrezGeneUrl'].append(gene_props['ncbiEntrezGeneUrl'])\n",
    "        \n",
    "        proteins = \"\"\n",
    "        if gene_props['proteins'] != []:\n",
    "            for i in range(len(gene_props['proteins'])):\n",
    "                proteins += gene_props['proteins'][i]['symbol']\n",
    "                if i != len(gene_props['proteins'])-1:\n",
    "                    proteins += ','\n",
    "        gene_prop_dict['Proteins'].append(proteins)\n",
    "                \n",
    "\n",
    "        root_family = \"\"\n",
    "        if gene_props['hgncRootFamilies'] != []:\n",
    "            for i in range(len(gene_props['hgncRootFamilies'])):\n",
    "                root_family += gene_props['hgncRootFamilies'][i]['name']\n",
    "                if i != len(gene_props['hgncRootFamilies'])-1:\n",
    "                    root_family += ','\n",
    "        gene_prop_dict['HgncRootFamilies'].append(root_family)\n",
    "        \n",
    "        \n",
    "    return_dict[num] = gene_prop_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e71d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_gene = pd.read_csv(\"graph_data/disease__gene.csv\",sep='\\t')\n",
    "\n",
    "gene_list = list(dis_gene['gene'])\n",
    "\n",
    "gene_lst = list(set(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cac7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = 40\n",
    "\n",
    "return_dict = Manager().dict()\n",
    "jobs = []\n",
    "\n",
    "for i in range(num_processes):\n",
    "    lb = i*math.ceil(len(gene_lst)/num_processes)\n",
    "    up = min((i+1)*math.ceil(len(gene_lst)/num_processes),len(gene_lst))\n",
    "    \n",
    "    p = Process(target=gene_properties,args=(gene_lst[lb:up],i,return_dict))\n",
    "    jobs.append(p)\n",
    "    p.start()\n",
    "    \n",
    "for process in jobs:\n",
    "    process.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "for i in range(len(return_dict)):\n",
    "    df_lst.append(pd.DataFrame(return_dict[i]))\n",
    "    \n",
    "df = pd.concat(df_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"graph_data/gene__nodes.csv\",sep='\\t',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553001d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run on terminal\n",
    "!polly files sync --workspace-id 9475 --source graph_data/ --destination polly://graph_data/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
